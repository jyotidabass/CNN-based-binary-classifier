{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **[Beginner] CNN-based Honey Bee Pollen Binary Classifier**\n---\nThis is a simple CNN model used to classify whether or not a bee is carrying pollen.   \nThis model it able to obtain over 90% accuracy with 571 training images on 143 test images.     \n \n*I will try to improve accuracy in the future with image augmentation techniques*\n\n# Table of Contents\n1. [Part 1: Organize the Dat](#Part 1: Organize the Data)\n2. [Part 2: Build the CNN model](#Part 2: Build the CNN model)\n3. [Part 3: Train the CNN mode](#Part 3: Train the CNN model)\n4. [Part 4: Analyze the CNN mode](#Part 4: Analyze the CNN mode)\n5. [Part 5: Retrain the Model with all the Training data](#Part 5: Retrain the Model with all the Training data)\n5. [Part 6: Test the Model](#Part 6: Test the Model)","metadata":{"_uuid":"234b886d748b1d917f80c7fbbc8d57c2d6257976"}},{"cell_type":"markdown","source":"<a name=\"Part 1: Organize the Data\"></a>\n## Part 1: Organize the Data    \n1. Import the images into a dataset\n2. Split the dataset into a training, validation, and testing sets","metadata":{"_uuid":"46a4109dd63f2e9fffa4e804532ee4d31aac4f02"}},{"cell_type":"code","source":"import glob, os \nfrom skimage import io, transform\nimport numpy as np\nimport matplotlib.pyplot as plt\npath=\"../input/pollendataset/PollenDataset/images/\"\nimlist= glob.glob(os.path.join(path, '*.jpg'))","metadata":{"_uuid":"2c1806b50645c06d62e4350e4bb790e159e9321d","execution":{"iopub.status.busy":"2022-06-20T07:43:23.256923Z","iopub.execute_input":"2022-06-20T07:43:23.257375Z","iopub.status.idle":"2022-06-20T07:43:23.266595Z","shell.execute_reply.started":"2022-06-20T07:43:23.257180Z","shell.execute_reply":"2022-06-20T07:43:23.265680Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def dataset(file_list,size=(300,180),flattened=False):\n\tdata = []\n\tfor i, file in enumerate(file_list):\n\t\timage = io.imread(file)\n\t\timage = transform.resize(image, size, mode='constant')\n\t\tif flattened:\n\t\t\timage = image.flatten()\n\n\t\tdata.append(image)\n\n\tlabels = [1 if f.split(\"/\")[-1][0] == 'P' else 0 for f in file_list]\n\n\treturn np.array(data), np.array(labels)","metadata":{"_uuid":"9371036fac44547841c3c5d869bb65b37b417af6","execution":{"iopub.status.busy":"2022-06-20T07:43:31.258374Z","iopub.execute_input":"2022-06-20T07:43:31.258659Z","iopub.status.idle":"2022-06-20T07:43:31.266206Z","shell.execute_reply.started":"2022-06-20T07:43:31.258609Z","shell.execute_reply":"2022-06-20T07:43:31.265301Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"* Load the dataset into the image tensor X\n* y will contain the labels for X","metadata":{"_uuid":"f5afb70c843cbefb16c5bf27fec362b975125798"}},{"cell_type":"code","source":"# Load the dataset (may take a few seconds)\nX,y=dataset(imlist)","metadata":{"_uuid":"2391ac30ed3963a5b87b7dacd1dfb1c8c84d7c6b","execution":{"iopub.status.busy":"2022-06-20T07:43:38.541864Z","iopub.execute_input":"2022-06-20T07:43:38.542222Z","iopub.status.idle":"2022-06-20T07:43:51.152655Z","shell.execute_reply.started":"2022-06-20T07:43:38.542171Z","shell.execute_reply":"2022-06-20T07:43:51.151916Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# X has the following structure: X[imageid, y,x,channel]\nprint('The length of X: ',len(X))  # data\nprint('The shape of X: ',X.shape)  # target\nprint('The shape of Y', y.shape)","metadata":{"_uuid":"4d5ce73ff1e8fd5725723c35e24969e9609cc6bd","execution":{"iopub.status.busy":"2022-06-20T07:43:54.779050Z","iopub.execute_input":"2022-06-20T07:43:54.779339Z","iopub.status.idle":"2022-06-20T07:43:54.786729Z","shell.execute_reply.started":"2022-06-20T07:43:54.779289Z","shell.execute_reply":"2022-06-20T07:43:54.785833Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"As displayed above there are **714**  tensor images in dataset X","metadata":{"_uuid":"0a83c64bd42e123c4e5897e5cf0e8697db917285"}},{"cell_type":"code","source":"print(X[1,:,: ,0]) #let's look into the pixel data for one of the images","metadata":{"_uuid":"739c537e27c73f1c975d7ba94515a3309853ef9a","execution":{"iopub.status.busy":"2022-06-20T07:44:02.156273Z","iopub.execute_input":"2022-06-20T07:44:02.156554Z","iopub.status.idle":"2022-06-20T07:44:02.163858Z","shell.execute_reply.started":"2022-06-20T07:44:02.156505Z","shell.execute_reply":"2022-06-20T07:44:02.162863Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"We do not need to scale the pixel values as they are already between 0-1\n### Now let's create the training, partial training,  valdiation, and testing sets </br>\n* We will split the dataset X and label matrix y into three partitions to achieve this\n* train_test_split module function from sklearn can automatically do this for us\n* Training dataset will be used to train the final model, partial training dataset is only used in conjunction with the validation dataset to ensure we do not overfit. (Determine ideal number of epoches)","metadata":{"_uuid":"633050b08f805974b2f4db186271fea3764fd6ea"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(\n\tX, y, test_size=0.20)\n\npartial_x_train, validation_x_train, partial_y_train, validation_y_train = train_test_split(\n\tx_train, y_train, test_size=0.15)","metadata":{"_uuid":"dd9e6aad7eee960cb589c08f355af99c5074b52d","execution":{"iopub.status.busy":"2022-06-20T07:44:09.864716Z","iopub.execute_input":"2022-06-20T07:44:09.865041Z","iopub.status.idle":"2022-06-20T07:44:10.959818Z","shell.execute_reply.started":"2022-06-20T07:44:09.864991Z","shell.execute_reply":"2022-06-20T07:44:10.958902Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"As a sanity check, let's check the length of each set...","metadata":{"_uuid":"e3ef83339b464d7eff599d3fd22a79f2668e9cd7"}},{"cell_type":"code","source":"print('The size of the training set: ',len(x_train))\nprint('The size of the partial training set: ',len(partial_x_train))\nprint('The size of the validation training set: ',len(validation_x_train))\nprint('The size of the testing set: ',len(x_test))","metadata":{"_uuid":"654e8ee58451215fa015786b91176b2039f0fcf5","execution":{"iopub.status.busy":"2022-06-20T07:44:17.320564Z","iopub.execute_input":"2022-06-20T07:44:17.320896Z","iopub.status.idle":"2022-06-20T07:44:17.328476Z","shell.execute_reply.started":"2022-06-20T07:44:17.320842Z","shell.execute_reply":"2022-06-20T07:44:17.327731Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Now that we have the training, partial training, validation, and testing set. It's time to design the CNN model...\n<a name=\"Part 2: Build the CNN model\"></a>\n## Part 2: Build the CNN model","metadata":{"_uuid":"ae1745664e4de35099f878d8820e3967d891d7a7"}},{"cell_type":"code","source":"from keras import layers\nfrom keras import models\nfrom keras import optimizers\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(64,(3,3), activation='relu', input_shape=(300,180,3)))  #input shape must be the match the input image tensor shape\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(64,(3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(128,(3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(128,(3,3), activation='relu'))\nmodel.add(layers.Conv2D(128,(3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(256,(3,3), activation='relu'))\nmodel.add(layers.Conv2D(256,(3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation = 'relu'))\nmodel.add(layers.Dense(1, activation = 'sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])","metadata":{"_uuid":"7dfefbe5000abcff57d74cb9300d66bfc01f4a95","execution":{"iopub.status.busy":"2022-06-20T07:44:26.450309Z","iopub.execute_input":"2022-06-20T07:44:26.450606Z","iopub.status.idle":"2022-06-20T07:44:26.951667Z","shell.execute_reply.started":"2022-06-20T07:44:26.450548Z","shell.execute_reply":"2022-06-20T07:44:26.950717Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Now we are ready to begin the training!\n<a name=\"Part 3: Train the CNN model\"></a>\n## Part 3: Train the CNN model","metadata":{"_uuid":"2739739ad41859f3f0f1aeabeb425c0c8c053462"}},{"cell_type":"code","source":"history = model.fit(\n    partial_x_train, \n    partial_y_train,\n    validation_data=(validation_x_train, validation_y_train),\n    epochs=100, \n    batch_size=15, \n    verbose =2) #hides some information while training","metadata":{"_uuid":"954dbfa91662b0583cde596fd14e651cdd8672c7","execution":{"iopub.status.busy":"2022-06-20T07:44:34.262233Z","iopub.execute_input":"2022-06-20T07:44:34.262526Z","iopub.status.idle":"2022-06-20T07:47:06.373563Z","shell.execute_reply.started":"2022-06-20T07:44:34.262475Z","shell.execute_reply":"2022-06-20T07:47:06.372894Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"<a name=\"Part 4: Analyze the CNN mode\"></a>\n## Part 4: Analyze the CNN mode","metadata":{"_uuid":"56a3e837ccc71ccfb0084d02a755d505638aaa43"}},{"cell_type":"code","source":"def smooth_curve(points, factor=0.8): #this function will make our plots more smooth\n\tsmoothed_points = []\n\tfor point in points:\n\t\tif smoothed_points:\n\t\t\tprevious = smoothed_points[-1]\n\t\t\tsmoothed_points.append(previous*factor+point*(1-factor))\n\t\telse:\n\t\t\tsmoothed_points.append(point)\n\treturn smoothed_points","metadata":{"_uuid":"7285226b908039bda3484b14445764bc7bff4629","execution":{"iopub.status.busy":"2022-06-20T07:47:51.883346Z","iopub.execute_input":"2022-06-20T07:47:51.883640Z","iopub.status.idle":"2022-06-20T07:47:51.889242Z","shell.execute_reply.started":"2022-06-20T07:47:51.883588Z","shell.execute_reply":"2022-06-20T07:47:51.888481Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n","metadata":{"_uuid":"31e77a48f96bd598e52b7e59805562dd08d15f63","execution":{"iopub.status.busy":"2022-06-20T07:48:28.583395Z","iopub.execute_input":"2022-06-20T07:48:28.583682Z","iopub.status.idle":"2022-06-20T07:48:28.588135Z","shell.execute_reply.started":"2022-06-20T07:48:28.583631Z","shell.execute_reply":"2022-06-20T07:48:28.587345Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"epochs = range(1, len(acc)+1)\nplt.plot(epochs, smooth_curve(acc), 'bo', label='Training acc')\nplt.plot(epochs, smooth_curve(val_acc), 'r-', label='Training acc')\nplt.legend()\nplt.title('Training and Validation Acc')\nplt.figure()\n\nplt.plot(epochs, smooth_curve(loss), 'bo', label='Training loss')\nplt.plot(epochs, smooth_curve(val_loss), 'r-', label='Training acc')\nplt.legend()\nplt.title('Training and Validation loss')\nplt.show()","metadata":{"_uuid":"e230d0838de32068ddb3600332a080aca7339890","execution":{"iopub.status.busy":"2022-06-20T07:48:34.582140Z","iopub.execute_input":"2022-06-20T07:48:34.582420Z","iopub.status.idle":"2022-06-20T07:48:34.980787Z","shell.execute_reply.started":"2022-06-20T07:48:34.582371Z","shell.execute_reply":"2022-06-20T07:48:34.979865Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Based on the plots above, it seems we start to overfit around 60 epochs!  \nWe will use around 60 epochs for our final training model.   \n**Result may vary**","metadata":{"_uuid":"c0841a81617490b23c359e1ac9927b3b81d8613b"}},{"cell_type":"markdown","source":"<a name=\"Part 5: Retrain the Model with all the Training data\"></a>\n## Part 5: Retrain the Model with all the Training data","metadata":{"_uuid":"c49027cae9b8d768604e68bc7ec57aeb925de150"}},{"cell_type":"code","source":"model1 = models.Sequential()\nmodel1.add(layers.Conv2D(64,(3,3), activation='relu', input_shape=(300,180,3)))  #input shape must be the match the input image tensor shape\nmodel1.add(layers.MaxPooling2D(2,2))\nmodel1.add(layers.Conv2D(64,(3,3), activation='relu'))\nmodel1.add(layers.MaxPooling2D(2,2))\nmodel1.add(layers.Conv2D(128,(3,3), activation='relu'))\nmodel1.add(layers.MaxPooling2D(2,2))\nmodel1.add(layers.Conv2D(128,(3,3), activation='relu'))\nmodel1.add(layers.Conv2D(128,(3,3), activation='relu'))\nmodel1.add(layers.MaxPooling2D(2,2))\nmodel1.add(layers.Conv2D(256,(3,3), activation='relu'))\nmodel1.add(layers.Conv2D(256,(3,3), activation='relu'))\nmodel1.add(layers.MaxPooling2D(2,2))\nmodel1.add(layers.Flatten())\nmodel1.add(layers.Dropout(0.5))\nmodel1.add(layers.Dense(512, activation = 'relu'))\nmodel1.add(layers.Dense(1, activation = 'sigmoid'))\n\nmodel1.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])\n\nhistory1 = model1.fit(\n    x_train, \n    y_train,\n    epochs=65, \n    batch_size=15, \n    verbose =2)","metadata":{"_uuid":"809b1f210f042e8032b2ef61c82fb4519adb8234","execution":{"iopub.status.busy":"2022-06-20T07:48:42.733405Z","iopub.execute_input":"2022-06-20T07:48:42.733723Z","iopub.status.idle":"2022-06-20T07:50:25.052492Z","shell.execute_reply.started":"2022-06-20T07:48:42.733658Z","shell.execute_reply":"2022-06-20T07:50:25.051830Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"<a name=\"Part 6: Test the Model\"></a>\n## Part 6: Test the Model","metadata":{"_uuid":"e266e2338b48326ef047bfec46849e28c45df0fe","trusted":true}},{"cell_type":"code","source":"test_loss, test_acc = model1.evaluate(x_test, y_test, steps=10)\nprint('The final test accuracy: ',test_acc)","metadata":{"_uuid":"4b650ce68aa0622cf0c127e00cec36749cd91460","execution":{"iopub.status.busy":"2022-06-20T07:50:32.654864Z","iopub.execute_input":"2022-06-20T07:50:32.655162Z","iopub.status.idle":"2022-06-20T07:50:35.517370Z","shell.execute_reply.started":"2022-06-20T07:50:32.655113Z","shell.execute_reply":"2022-06-20T07:50:35.515931Z"},"trusted":true},"execution_count":18,"outputs":[]}]}